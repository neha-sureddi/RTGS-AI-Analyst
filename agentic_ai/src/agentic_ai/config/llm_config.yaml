# LLM Configuration for Agentic AI System
# This file defines which LLM models to use for different types of tasks

# Model configurations
models:
  # Gemini Flash 1.5 - Preferred model for all agents
  gemini_flash:
    provider: "gemini"
    model_name: "gemini-1.5-flash-latest"
    api_key_env: "GOOGLE_API_KEY" # also supports GEMINI_API_KEY via code
    description: "Google's efficient model for all tasks"
    capabilities:
      - all

  # TinyLlama - Fallback only
  tinyllama:
    provider: "ollama"
    model_name: "tinyllama"
    api_base: "http://localhost:11434"
    description: "Local fallback for when Gemini key is missing"
    capabilities:
      - fallback

# Agent-to-model mapping
agent_model_mapping:
  data_ingestion_agent: "gemini_flash"
  data_standardization_agent: "gemini_flash"
  analysis_agent: "gemini_flash"
  policy_insights_agent: "gemini_flash"

# Fallback configuration
fallback_model: "tinyllama"

model_selection:
  # No dynamic selection needed; Gemini default, TinyLlama fallback only
